{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_adversarial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGkZ15Jmt1VM"
      },
      "source": [
        "#Adversarial Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Vf1v6Ashmc"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import recall_score, confusion_matrix"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfEBJ5m1sst3"
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[+-_/(){}!^?<>\"''\\[\\]\\|,;:.]')\n",
        "# data cleaning\n",
        "def clean_text(text):       # return terms with no duplication\n",
        "  # change to lower-case\n",
        "  #text = str(text).lower()\n",
        "  text = text.replace('\\n', ' ')\n",
        "  text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "  text = list(set(text.split(' ')))\n",
        "  return text\n",
        "\n",
        "def clean_text1(text):       # return terms with duplications\n",
        "  # change to lower-case\n",
        "  #text = str(text).lower()\n",
        "  text = text.replace('\\n', ' ')\n",
        "  text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "  text = list(text.split(' '))\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRqTKiFUsnBL"
      },
      "source": [
        "n_spam = 432           # number of spam emails\n",
        "n_legit = 2170            # number of legit emails\n",
        "n_email = n_spam + n_legit      # total number of emails"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN5cioW_sVor",
        "outputId": "b1f0e3b1-69f7-47ab-ef5b-7f4211f8f103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "# read the 1000 terms occurrence data \n",
        "df0 = pd.read_csv('term1000_occur.csv')\n",
        "df0.index = df0['Unnamed: 0']\n",
        "df0.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "\n",
        "nterm_s = 454430      # total number of terms in spam\n",
        "nterm_l = 1488668      # total number of terms in legit\n",
        "print('Total number of terms in spam:', nterm_s)\n",
        "print('Total number of terms in legit:', nterm_l)\n",
        "\n",
        "# get topN terms, N = 10\n",
        "df1 = df0.iloc[0:10]\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of terms in spam: 454430\n",
            "Total number of terms in legit: 1488668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#term in spam</th>\n",
              "      <th>#term in legit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <td>19</td>\n",
              "      <td>7593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remove</th>\n",
              "      <td>415</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>free</th>\n",
              "      <td>905</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university</th>\n",
              "      <td>39</td>\n",
              "      <td>5252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>money</th>\n",
              "      <td>903</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>click</th>\n",
              "      <td>232</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>market</th>\n",
              "      <td>454</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>our</th>\n",
              "      <td>1090</td>\n",
              "      <td>623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business</th>\n",
              "      <td>734</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>today</th>\n",
              "      <td>243</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            #term in spam  #term in legit\n",
              "Unnamed: 0                               \n",
              "language               19            7593\n",
              "remove                415              30\n",
              "free                  905             196\n",
              "university             39            5252\n",
              "money                 903              75\n",
              "click                 232              22\n",
              "market                454              58\n",
              "our                  1090             623\n",
              "business              734              90\n",
              "today                 243             104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhtZ7qa33lby"
      },
      "source": [
        "##Baseline classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDw7hi62qWlw"
      },
      "source": [
        "# use multinomial NB with binary features as the baseline algorithm\n",
        "def Multinomial_B(text, df, n_spam=n_spam, n_legit=n_legit, n_email=n_email, nterm_s=nterm_s, nterm_l=nterm_l):\n",
        "  ##\n",
        "  Pr_s = n_spam/n_email\n",
        "  Pr_l = n_legit/n_email\n",
        "  Pr_il = 1\n",
        "  Pr_is = 1\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    if df.index[i] in text:\n",
        "      Pr_is = ((df.iloc[i][0]+1)/(nterm_s+2))*Pr_is\n",
        "      Pr_il = ((df.iloc[i][1]+1)/(nterm_l+2))*Pr_il\n",
        "\n",
        "  Pr_si = Pr_is * Pr_s     # Pr of spam\n",
        "  Pr_li = Pr_il * Pr_l     # Pr of legit\n",
        "\n",
        "  return Pr_si/Pr_li"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqSTaz2Ks9dR",
        "outputId": "f5d74864-05aa-4ec5-ebc7-095aa1c40761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# test\n",
        "result = []\n",
        "result_true = []\n",
        "\n",
        "# read the test data and split them into spam and legit\n",
        "root = '/content/drive/My Drive/Colab Notebooks/data/lemm_stop/part10'\n",
        "file_names = os.listdir(root)\n",
        "#file_names = file_names[150:]\n",
        "\n",
        "for file in file_names:\n",
        "  f = open(root + '/' + file, 'r')\n",
        "  text = f.read()\n",
        "  text = clean_text(text)     # unique terms\n",
        "  if file[0] != 's':\n",
        "    result_true.append(0)\n",
        "  else:\n",
        "    result_true.append(1)\n",
        "  f.close()\n",
        "\n",
        "  # prediction\n",
        "  pred = Multinomial_B(text, df1)\n",
        "\n",
        "  if pred > 1:\n",
        "    result.append(1)\n",
        "  else:\n",
        "    result.append(0)\n",
        "\n",
        "print('False Negative Rate:', 1-recall_score(result_true, result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False Negative Rate: 0.08163265306122447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjEUGFSTOFzj"
      },
      "source": [
        "The FNRate is very low, which means those predictions of ham are correct.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYlZ-7bD3pUp"
      },
      "source": [
        "##Adversarial's strategy\n",
        "\n",
        "The adversary uses the **ADD-WORDS** strategy. Adding a term to an email incurs unit cost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcUWwKHquTRo"
      },
      "source": [
        "# compute the reduction obtained by adding/removing each term in the 10 features\n",
        "weight = {}\n",
        "for i in range(len(df1)):\n",
        "  term = df1.index[i]\n",
        "  Pr_is = ((df1.iloc[i][0]+1)/(nterm_s+2))\n",
        "  Pr_il = ((df1.iloc[i][1]+1)/(nterm_l+2))\n",
        "\n",
        "  LO_1 = np.log(Pr_is/Pr_il)\n",
        "  LO_0 = np.log((1-Pr_is)/(1-Pr_il))\n",
        "  \n",
        "  delta = max(LO_0-LO_1, 0)\n",
        "  weight[term] = delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFbwGNQ_IzI5",
        "outputId": "998b5620-053e-43d6-fc56-395b829ddcd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "df_w = pd.DataFrame(weight.values(), index=weight.keys(), columns=['weight'])\n",
        "df_w.sort_values(by=['weight'], inplace=True, ascending=False)\n",
        "print('terms to be add:')\n",
        "df_add = df_w[df_w['weight']>0]\n",
        "df_add"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "terms to be add:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <td>4.757862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university</th>\n",
              "      <td>3.694532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              weight\n",
              "language    4.757862\n",
              "university  3.694532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n-zFZSwJc5E",
        "outputId": "582bca5c-e31d-4a2c-b52a-0f32cfd27564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# test\n",
        "result = []\n",
        "result_true = []\n",
        "cost = 0\n",
        "\n",
        "# read the test data and split them into spam and legit\n",
        "root = '/content/drive/My Drive/Colab Notebooks/data/lemm_stop/part10'\n",
        "file_names = os.listdir(root)\n",
        "n_spam_test = 0    # total number of spam emails\n",
        "\n",
        "for file in file_names:\n",
        "  f = open(root + '/' + file, 'r')\n",
        "  text = f.read()\n",
        "  f.close() \n",
        "  text = clean_text(text)\n",
        "\n",
        "  if file[0] != 's':\n",
        "    result_true.append(0)\n",
        "  else:              # modify spam emails\n",
        "    result_true.append(1)\n",
        "    n_spam_test += 1\n",
        "    pred = Multinomial_B(text, df1)\n",
        "\n",
        "    if pred > 1:\n",
        "      # add terms if not exist\n",
        "      term = df_add.index[0]   # only adding the first term(with highest weight)\n",
        "      if term not in text:\n",
        "        text.append(term)\n",
        "        cost += 1\n",
        "      pred = Multinomial_B(text, df1)\n",
        "\n",
        "      if pred > 1:\n",
        "        term = df_add.index[1]   # add the second term(binary feature)\n",
        "        if term not in text:\n",
        "          text.append(term)\n",
        "          cost += 1\n",
        "  \n",
        "  # prediction\n",
        "  pred = Multinomial_B(text, df1)\n",
        "\n",
        "  if pred > 1:\n",
        "    result.append(1)\n",
        "  else:\n",
        "    result.append(0)\n",
        "\n",
        "cm = confusion_matrix(result_true, result)\n",
        "print('After the attacker\\'s modifications to test emails')\n",
        "print('False Negative Rate:', 1-recall_score(result_true, result))\n",
        "print('Average cost per spam:', cost/n_spam_test)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After the attacker's modifications to test emails\n",
            "False Negative Rate: 0.7959183673469388\n",
            "Average cost per spam: 1.469387755102041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htFq4aLpO0uD"
      },
      "source": [
        "After adding some non-spam features in the test emails, the FNRate increases a lot which means many spam emails are predicted as ham now.\n",
        "\n",
        "This is the highest FNRate I can get since all the two non-spam features have been added in the email which was predicted as spam, and since the classifier I used is based on binary feature, we cannot add same features multiple times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ8IlIawSpe_",
        "outputId": "49643229-f22d-4ea4-f8ca-a1c33c962f95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print([result])\n",
        "print([result_true])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyoYNIcj-CDq"
      },
      "source": [
        "##Classifier response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWHKyj4H6s1o",
        "outputId": "1569e9f4-df39-4441-82c0-926f9cadd5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "############## adversary's modification on train data ###################\n",
        "'''\n",
        "legit = []\n",
        "spam = []\n",
        "\n",
        "# read the test data and split them into spam and legit\n",
        "for i in range(1, 10):\n",
        "  root = '/content/drive/My Drive/Colab Notebooks/data/lemm_stop/part' + str(i)\n",
        "  file_names = os.listdir(root)\n",
        "\n",
        "  for file in file_names:\n",
        "    f = open(root + '/' + file, 'r')\n",
        "    text = f.read()\n",
        "    text = clean_text1(text)\n",
        "    \n",
        "    if file[0] != 's':\n",
        "      legit.append(text)\n",
        "    else:                   # add terms in spam\n",
        "      pred = Multinomial_B(text, df1)\n",
        "\n",
        "      if pred > 1:\n",
        "        # add terms if not exist\n",
        "        term = df_add.index[0]   # only adding the first term(with highest weight)\n",
        "        if term not in text:\n",
        "          text.append(term)\n",
        "        pred = Multinomial_B(text, df1)\n",
        "\n",
        "        if pred > 1:\n",
        "          term = df_add.index[1]   # add the second term(binary feature)\n",
        "          if term not in text:\n",
        "            text.append(term)  \n",
        "      spam.append(text)\n",
        "    f.close()\n",
        "\n",
        "print(len(spam))\n",
        "print(len(legit))\n",
        "'''"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "432\n",
            "2170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4JE1Sx0N6hH"
      },
      "source": [
        "'''\n",
        "occur = {}\n",
        "for term in df1.index:\n",
        "  #term = term.replace(\"'\", \"\")\n",
        "  spam_occ = 0    # number of spam email with term\n",
        "  legit_occ = 0    # number of legit email with term\n",
        "  # compute the number of legit and spam with each term in corpus\n",
        "  for i in range(len(spam)):\n",
        "    for j in range(len(spam[i])):\n",
        "      if term == spam[i][j]:\n",
        "        spam_occ += 1\n",
        "  for i in range(len(legit)):\n",
        "    for j in range(len(legit[i])):\n",
        "      if term == legit[i][j]:\n",
        "        legit_occ += 1\n",
        "  occur[term] = [spam_occ, legit_occ]\n",
        "'''"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmA6DRrKOrxD"
      },
      "source": [
        "'''\n",
        "df0 = pd.DataFrame(data=occur.values(), index=occur.keys(), columns=['#term in spam', '#term in legit'])\n",
        "df0.to_csv('term10_occur.csv')\n",
        "'''"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4m957DcO2dU",
        "outputId": "5e89d946-78f9-41af-febd-3be764240920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "# read the 1000 terms occurrence data \n",
        "df0 = pd.read_csv('term10_occur.csv')\n",
        "df0.index = df0['Unnamed: 0']\n",
        "df0.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "'''\n",
        "nterm_s = 0\n",
        "nterm_l = 0\n",
        "for i in range(len(spam)):\n",
        "  nterm_s += len(spam[i])\n",
        "for i in range(len(legit)):\n",
        "  nterm_l += len(legit[i])\n",
        "'''\n",
        "nterm_s = 455076\n",
        "nterm_l = 1488668\n",
        "print('Total number of terms in spam:', nterm_s)\n",
        "print('Total number of terms in legit:', nterm_l)\n",
        "\n",
        "# get topN terms, N = 10\n",
        "df0"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of terms in spam: 455076\n",
            "Total number of terms in legit: 1488668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#term in spam</th>\n",
              "      <th>#term in legit</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>language</th>\n",
              "      <td>404</td>\n",
              "      <td>7593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remove</th>\n",
              "      <td>415</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>free</th>\n",
              "      <td>905</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university</th>\n",
              "      <td>300</td>\n",
              "      <td>5252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>money</th>\n",
              "      <td>903</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>click</th>\n",
              "      <td>232</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>market</th>\n",
              "      <td>454</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>our</th>\n",
              "      <td>1090</td>\n",
              "      <td>623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>business</th>\n",
              "      <td>734</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>today</th>\n",
              "      <td>243</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            #term in spam  #term in legit\n",
              "Unnamed: 0                               \n",
              "language              404            7593\n",
              "remove                415              30\n",
              "free                  905             196\n",
              "university            300            5252\n",
              "money                 903              75\n",
              "click                 232              22\n",
              "market                454              58\n",
              "our                  1090             623\n",
              "business              734              90\n",
              "today                 243             104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw3aR84yWgD7",
        "outputId": "5623f59e-bfd7-4475-b432-240698ef00b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# test\n",
        "result = []\n",
        "result_true = []\n",
        "\n",
        "# read the test data and split them into spam and legit\n",
        "root = '/content/drive/My Drive/Colab Notebooks/data/lemm_stop/part10'\n",
        "file_names = os.listdir(root)\n",
        "\n",
        "for file in file_names:\n",
        "  f = open(root + '/' + file, 'r')\n",
        "  text = f.read()\n",
        "  f.close() \n",
        "  text = clean_text(text)\n",
        "\n",
        "  if file[0] != 's':\n",
        "    result_true.append(0)\n",
        "  else:              # modify spam emails\n",
        "    result_true.append(1)\n",
        "    pred = Multinomial_B(text, df1)\n",
        "\n",
        "    if pred > 1:\n",
        "      # add terms if not exist\n",
        "      term = df_add.index[0]   # only adding the first term(with highest weight)\n",
        "      if term not in text:\n",
        "        text.append(term)\n",
        "      pred = Multinomial_B(text, df1)\n",
        "\n",
        "      if pred > 1:\n",
        "        term = df_add.index[1]   # add the second term(binary feature)\n",
        "        if term not in text:\n",
        "          text.append(term)\n",
        "  \n",
        "  # prediction\n",
        "  pred = Multinomial_B(text, df0)\n",
        "\n",
        "  if pred > 1:\n",
        "    result.append(1)\n",
        "  else:\n",
        "    result.append(0)\n",
        "\n",
        "print('After the response of classifier')\n",
        "print('False Negative Rate:', 1-recall_score(result_true, result))\n",
        "cm = confusion_matrix(result_true, result)\n",
        "print('False Positive Rate:', cm[0][1]/(cm[0][0]+cm[0][1]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After the response of classifier\n",
            "False Negative Rate: 0.30612244897959184\n",
            "False Positive Rate: 0.15289256198347106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piIAyu-NcgWd",
        "outputId": "928d7d3e-f409-4fb5-f468-40bfe93dab60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print([result])\n",
        "print([result_true])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]]\n",
            "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKeqQ66ffcMY"
      },
      "source": [
        "**Report**\n",
        "\n",
        "* Baseline result:\n",
        "\n",
        "False Negative Rate: 0.08163265306122447\n",
        "\n",
        "* After the attacker's modifications to test emails:\n",
        "\n",
        "False Negative Rate: 0.7959183673469388\n",
        "\n",
        "Average cost per spam: 1.469387755102041\n",
        "\n",
        "* After the response of classifier:\n",
        "\n",
        "False Negative Rate: 0.30612244897959184\n",
        "\n",
        "False Positive Rate: 0.15289256198347106"
      ]
    }
  ]
}